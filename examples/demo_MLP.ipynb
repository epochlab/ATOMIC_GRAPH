{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atomic_graph.engine import Value\n",
    "from atomic_graph.nn import Neuron, Layer, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "    ]\n",
    "\n",
    "ys = [1.0, -1.0, -1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.5958519790052343\n",
      "1 2.346919091164896\n",
      "2 0.3800986457379\n",
      "3 0.10009719132052217\n",
      "4 0.07688277393815732\n",
      "5 0.0633185852279058\n",
      "6 0.05376767255120683\n",
      "7 0.0466315615423811\n",
      "8 0.04110061619952875\n",
      "9 0.03669483242091831\n",
      "10 0.033107897832560976\n",
      "11 0.03013469667091634\n",
      "12 0.027632752878986214\n",
      "13 0.025500110634934632\n",
      "14 0.023661962744858878\n",
      "15 0.022062232291214325\n",
      "16 0.02065809251715568\n",
      "17 0.019416296495507128\n",
      "18 0.01831065746779059\n",
      "19 0.017320281136347912\n",
      "20 0.016428301339600666\n",
      "21 0.015620960003528563\n",
      "22 0.014886927114367197\n",
      "23 0.014216790951134142\n",
      "24 0.0136026710052852\n",
      "25 0.01303792058323315\n",
      "26 0.012516895832173419\n",
      "27 0.012034774559486563\n",
      "28 0.011587412797448035\n",
      "29 0.01117123027673449\n",
      "30 0.010783118253861142\n",
      "31 0.010420364778656183\n",
      "32 0.010080593681675838\n",
      "33 0.009761714439267866\n",
      "34 0.009461880725929326\n",
      "35 0.009179455952342182\n",
      "36 0.008912984457099045\n",
      "37 0.008661167301999546\n",
      "38 0.008422841837421934\n",
      "39 0.00819696437198984\n",
      "40 0.007982595411506383\n",
      "41 0.007778887034740684\n",
      "42 0.007585072054682791\n",
      "43 0.007400454678256364\n",
      "44 0.007224402428904127\n",
      "45 0.007056339137768458\n",
      "46 0.006895738842536666\n",
      "47 0.006742120460076552\n",
      "48 0.006595043121039541\n",
      "49 0.006454102072665139\n",
      "50 0.006318925070866091\n",
      "51 0.006189169194931886\n",
      "52 0.006064518028348634\n",
      "53 0.00594467915768642\n",
      "54 0.005829381948566017\n",
      "55 0.005718375563630748\n",
      "56 0.005611427192424081\n",
      "57 0.005508320467268598\n",
      "58 0.005408854042791622\n",
      "59 0.005312840319755776\n",
      "60 0.005220104296416522\n",
      "61 0.005130482532818372\n",
      "62 0.005043822215312758\n",
      "63 0.004959980310189855\n",
      "64 0.004878822796697953\n",
      "65 0.0048002239709162\n",
      "66 0.004724065812978245\n",
      "67 0.004650237411035953\n",
      "68 0.004578634436128306\n",
      "69 0.004509158662795066\n",
      "70 0.004441717530863029\n",
      "71 0.004376223744346634\n",
      "72 0.004312594903854836\n",
      "73 0.0042507531692905064\n",
      "74 0.004190624949975958\n",
      "75 0.004132140619643073\n",
      "76 0.00407523425399613\n",
      "77 0.004019843388793354\n",
      "78 0.003965908796603145\n",
      "79 0.003913374280578628\n",
      "80 0.0038621864837587137\n",
      "81 0.003812294712551611\n",
      "82 0.003763650773188012\n",
      "83 0.0037162088200478954\n",
      "84 0.003669925214869036\n",
      "85 0.0036247583959393816\n",
      "86 0.0035806687564584223\n",
      "87 0.003537618531327896\n",
      "88 0.003495571691699645\n",
      "89 0.0034544938466685117\n",
      "90 0.003414352151553033\n",
      "91 0.0033751152222556186\n",
      "92 0.0033367530552380416\n",
      "93 0.00329923695268827\n",
      "94 0.0032625394524904644\n",
      "95 0.003226634262643459\n",
      "96 0.003191496199801605\n",
      "97 0.0031571011316395684\n",
      "98 0.0031234259227670503\n",
      "99 0.0030904483839411944\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "\n",
    "    #forward pass\n",
    "    ypred = [model(x) for x in xs]\n",
    "    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))     #mean-squared error\n",
    "\n",
    "    #backward pass\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # update - stocastic gradient descent\n",
    "    for p in model.parameters():\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    print(k, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9753636756242489),\n",
       " Value(data=-0.9866230495909916),\n",
       " Value(data=-0.9654651334858398),\n",
       " Value(data=0.9666548339665547)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e22c083f026c7769b83b8857fa3ac4d22c31dd61e89868550b0afe4a500a3cf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

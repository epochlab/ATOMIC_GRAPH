{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd.engine import Value\n",
    "from autograd.nn import Neuron, Layer, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "    ]\n",
    "\n",
    "ys = [1.0, -1.0, -1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.943234349180891\n",
      "1 3.145803704550727\n",
      "2 2.289092646715775\n",
      "3 2.1164622312543573\n",
      "4 2.5685218309013615\n",
      "5 2.0887041279526826\n",
      "6 0.41522648400777196\n",
      "7 0.04667607324585887\n",
      "8 0.04070860633315142\n",
      "9 0.03604039842790458\n",
      "10 0.032290794020607264\n",
      "11 0.029215384369132947\n",
      "12 0.026649460579408656\n",
      "13 0.024477806274052775\n",
      "14 0.022617366169293156\n",
      "15 0.021006754849420328\n",
      "16 0.019599631276141068\n",
      "17 0.018360366642896177\n",
      "18 0.01726112763416792\n",
      "19 0.016279862681836954\n",
      "20 0.01539888088853901\n",
      "21 0.014603829651477017\n",
      "22 0.01388294638901609\n",
      "23 0.013226502384693556\n",
      "24 0.012626383637277722\n",
      "25 0.012075770954328558\n",
      "26 0.011568892963082288\n",
      "27 0.011100833394945532\n",
      "28 0.010667379249829098\n",
      "29 0.010264900090766357\n",
      "30 0.009890251285451377\n",
      "31 0.009540695842460358\n",
      "32 0.009213840812622867\n",
      "33 0.008907585192364686\n",
      "34 0.008620076979355731\n",
      "35 0.008349677562841745\n",
      "36 0.008094932031449729\n",
      "37 0.007854544285219507\n",
      "38 0.007627356071247721\n",
      "39 0.007412329241740475\n",
      "40 0.007208530672641088\n",
      "41 0.007015119390004434\n",
      "42 0.006831335537102853\n",
      "43 0.006656490883215926\n",
      "44 0.006489960629207019\n",
      "45 0.006331176308369315\n",
      "46 0.006179619615960812\n",
      "47 0.006034817029124849\n",
      "48 0.005896335101892142\n",
      "49 0.005763776338749452\n",
      "50 0.005636775565681264\n",
      "51 0.005514996730296576\n",
      "52 0.005398130073168491\n",
      "53 0.005285889621245139\n",
      "54 0.005178010961472083\n",
      "55 0.005074249258856738\n",
      "56 0.00497437748831843\n",
      "57 0.004878184853975132\n",
      "58 0.004785475373156707\n",
      "59 0.004696066605518471\n",
      "60 0.004609788510251008\n",
      "61 0.0045264824166167\n",
      "62 0.004446000094953657\n",
      "63 0.0043682029169256655\n",
      "64 0.004292961095202279\n",
      "65 0.0042201529939663715\n",
      "66 0.004149664502692112\n",
      "67 0.004081388466541661\n",
      "68 0.004015224167515274\n",
      "69 0.003951076851171183\n",
      "70 0.0038888572943274894\n",
      "71 0.00382848140967729\n",
      "72 0.0037698698837017124\n",
      "73 0.0037129478446650773\n",
      "74 0.0036576445578242133\n",
      "75 0.003603893145292654\n",
      "76 0.003551630328270866\n",
      "77 0.003500796189592401\n",
      "78 0.003451333954748082\n",
      "79 0.0034031897897368623\n",
      "80 0.0033563126142585665\n",
      "81 0.0033106539289111166\n",
      "82 0.0032661676551858886\n",
      "83 0.0032228099871724437\n",
      "84 0.003180539253987886\n",
      "85 0.0031393157920390985\n",
      "86 0.003099101826310533\n",
      "87 0.0030598613599438548\n",
      "88 0.0030215600714441136\n",
      "89 0.0029841652189061423\n",
      "90 0.0029476455507101464\n",
      "91 0.002911971222183753\n",
      "92 0.002877113717772035\n",
      "93 0.002843045778296469\n",
      "94 0.002809741332920257\n",
      "95 0.002777175435469398\n",
      "96 0.002745324204788569\n",
      "97 0.0027141647688376704\n",
      "98 0.0026836752122588025\n",
      "99 0.0026538345271659076\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "\n",
    "    #forward pass\n",
    "    ypred = [model(x) for x in xs]\n",
    "    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))     #mean-squared error\n",
    "\n",
    "    #backward pass\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # update - stocastic gradient descent\n",
    "    for p in model.parameters():\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    print(k, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9726418817373783),\n",
       " Value(data=-0.9778064726479462),\n",
       " Value(data=-0.9671180652028032),\n",
       " Value(data=0.9817902883064874)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5d5a83eaedeee84420ab7678f633035701ff9e0d304ade9ef1d8f9285347459"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

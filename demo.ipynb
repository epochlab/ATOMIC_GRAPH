{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd.engine import Value\n",
    "from autograd.nn import Neuron, Layer, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "    ]\n",
    "\n",
    "ys = [1.0, -1.0, -1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.4721883425278177\n",
      "1 2.2829034935751245\n",
      "2 0.22069214417486552\n",
      "3 0.07916494371926044\n",
      "4 0.05794494912057441\n",
      "5 0.04662724388938358\n",
      "6 0.03922650274444532\n",
      "7 0.033900596373968285\n",
      "8 0.029848563564026348\n",
      "9 0.02664988758591593\n",
      "10 0.024056483167729726\n",
      "11 0.021910160963497016\n",
      "12 0.020104336454341117\n",
      "13 0.01856417424904408\n",
      "14 0.017235413328091594\n",
      "15 0.016077674940941068\n",
      "16 0.015060255883485744\n",
      "17 0.014159379240300082\n",
      "18 0.013356339283711306\n",
      "19 0.01263621568894615\n",
      "20 0.011986961690944237\n",
      "21 0.011398744453810939\n",
      "22 0.010863459494387185\n",
      "23 0.010374367657119516\n",
      "24 0.009925819923611672\n",
      "25 0.009513046181691964\n",
      "26 0.009131991238690521\n",
      "27 0.008779186186886143\n",
      "28 0.008451646536702198\n",
      "29 0.008146790838302456\n",
      "30 0.007862375142340745\n",
      "31 0.00759643981895122\n",
      "32 0.007347266101813515\n",
      "33 0.0071133403462941\n",
      "34 0.006893324452111955\n",
      "35 0.006686031246594881\n",
      "36 0.006490403885832532\n",
      "37 0.0063054985301916906\n",
      "38 0.006130469703712685\n",
      "39 0.0059645578654190755\n",
      "40 0.005807078812993992\n",
      "41 0.005657414611837011\n",
      "42 0.00551500579984395\n",
      "43 0.005379344663821118\n",
      "44 0.005249969419874269\n",
      "45 0.005126459159390985\n",
      "46 0.005008429445891709\n",
      "47 0.004895528467229989\n",
      "48 0.004787433663289469\n",
      "49 0.0046838487621623515\n",
      "50 0.004584501168357646\n",
      "51 0.004489139655316752\n",
      "52 0.004397532321754346\n",
      "53 0.004309464777372663\n",
      "54 0.004224738528535573\n",
      "55 0.004143169538714892\n",
      "56 0.004064586942076934\n",
      "57 0.003988831891578819\n",
      "58 0.0039157565254854\n",
      "59 0.0038452230383766274\n",
      "60 0.003777102844553193\n",
      "61 0.0037112758233194616\n",
      "62 0.003647629636966343\n",
      "63 0.003586059113433111\n",
      "64 0.0035264656866199648\n",
      "65 0.003468756888181562\n",
      "66 0.0034128458853735374\n",
      "67 0.0033586510601671827\n",
      "68 0.0033060956254063883\n",
      "69 0.003255107274267273\n",
      "70 0.0032056178597057545\n",
      "71 0.003157563100949168\n",
      "72 0.003110882314413271\n",
      "73 0.0030655181667113593\n",
      "74 0.0030214164476728284\n",
      "75 0.0029785258615097916\n",
      "76 0.0029367978344651295\n",
      "77 0.0028961863374476586\n",
      "78 0.0028566477223129156\n",
      "79 0.002818140570582881\n",
      "80 0.0027806255535188728\n",
      "81 0.0027440653025676406\n",
      "82 0.002708424289297137\n",
      "83 0.002673668714022105\n",
      "84 0.0026397664023967184\n",
      "85 0.002606686709318462\n",
      "86 0.002574400429548619\n",
      "87 0.0025428797145093723\n",
      "88 0.0025120979947662334\n",
      "89 0.0024820299077489144\n",
      "90 0.0024526512303029574\n",
      "91 0.002423938815700693\n",
      "92 0.0023958705347720006\n",
      "93 0.002368425220844568\n",
      "94 0.0023415826182100266\n",
      "95 0.0023153233338555086\n",
      "96 0.0022896287922228547\n",
      "97 0.0022644811927761722\n",
      "98 0.002239863470177254\n",
      "99 0.002215759256884115\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "\n",
    "    #forward pass\n",
    "    ypred = [model(x) for x in xs]\n",
    "    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))     #mean-squared error\n",
    "\n",
    "    #backward pass\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # update - stocastic gradient descent\n",
    "    for p in model.parameters():\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    print(k, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9794211332091612),\n",
       " Value(data=-0.9913780490523059),\n",
       " Value(data=-0.9736568114705332),\n",
       " Value(data=0.9680005019032243)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e22c083f026c7769b83b8857fa3ac4d22c31dd61e89868550b0afe4a500a3cf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

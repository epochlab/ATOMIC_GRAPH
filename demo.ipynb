{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd.engine import Value\n",
    "from autograd.nn import Neuron, Layer, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "    ]\n",
    "\n",
    "ys = [1.0, -1.0, -1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.530985600405283\n",
      "1 2.0357170543410557\n",
      "2 2.6839101012941797\n",
      "3 0.1301722644477629\n",
      "4 0.07971848382947684\n",
      "5 0.0656152151732884\n",
      "6 0.05662496733676993\n",
      "7 0.049988978814335346\n",
      "8 0.04478521184559339\n",
      "9 0.04056405532110266\n",
      "10 0.03706109043228212\n",
      "11 0.03410405981531254\n",
      "12 0.03157359432648733\n",
      "13 0.029383488014652386\n",
      "14 0.02746958431365057\n",
      "15 0.025783007332992484\n",
      "16 0.02428580692094234\n",
      "17 0.02294804059161168\n",
      "18 0.021745755685795853\n",
      "19 0.020659558125495848\n",
      "20 0.019673575503905694\n",
      "21 0.018774692139537214\n",
      "22 0.01795197578946795\n",
      "23 0.0171962419635983\n",
      "24 0.01649971865219408\n",
      "25 0.015855785398123642\n",
      "26 0.01525876813373498\n",
      "27 0.014703776341907972\n",
      "28 0.014186572687850823\n",
      "29 0.013703467809581923\n",
      "30 0.013251234780218292\n",
      "31 0.012827039082377723\n",
      "32 0.012428380911126647\n",
      "33 0.012053047347411935\n",
      "34 0.011699072488441042\n",
      "35 0.011364704033886303\n",
      "36 0.011048375141807992\n",
      "37 0.0107486806107303\n",
      "38 0.010464356632447802\n",
      "39 0.010194263507111152\n",
      "40 0.009937370827718993\n",
      "41 0.009692744732604976\n",
      "42 0.009459536897318481\n",
      "43 0.009236974995587139\n",
      "44 0.009024354405967478\n",
      "45 0.008821030978744418\n",
      "46 0.008626414708499489\n",
      "47 0.00843996418296825\n",
      "48 0.008261181699485264\n",
      "49 0.00808960895734769\n",
      "50 0.007924823248520918\n",
      "51 0.007766434080812335\n",
      "52 0.0076140801773937426\n",
      "53 0.007467426804714477\n",
      "54 0.007326163387697312\n",
      "55 0.0071900013768803365\n",
      "56 0.007058672337042755\n",
      "57 0.006931926230984866\n",
      "58 0.00680952987564616\n",
      "59 0.006691265550739003\n",
      "60 0.006576929742636278\n",
      "61 0.006466332008445297\n",
      "62 0.006359293947086293\n",
      "63 0.006255648265818464\n",
      "64 0.006155237932059153\n",
      "65 0.006057915401556708\n",
      "66 0.0059635419150308976\n",
      "67 0.005871986856310731\n",
      "68 0.00578312716579793\n",
      "69 0.005696846803781535\n",
      "70 0.0056130362587379105\n",
      "71 0.0055315920962856965\n",
      "72 0.005452416544934694\n",
      "73 0.005375417115179562\n",
      "74 0.005300506248854827\n",
      "75 0.0052276009959872655\n",
      "76 0.005156622716667383\n",
      "77 0.005087496805713149\n",
      "78 0.0050201524381217\n",
      "79 0.004954522333504464\n",
      "80 0.004890542537877042\n",
      "81 0.004828152221333236\n",
      "82 0.004767293490272313\n",
      "83 0.004707911212975601\n",
      "84 0.004649952857439481\n",
      "85 0.004593368340473946\n",
      "86 0.004538109887165463\n",
      "87 0.00448413189988469\n",
      "88 0.00443139083609256\n",
      "89 0.004379845094264027\n",
      "90 0.0043294549073085815\n",
      "91 0.004280182242919629\n",
      "92 0.004231990710334329\n",
      "93 0.004184845473028078\n",
      "94 0.004138713166909067\n",
      "95 0.00409356182361287\n",
      "96 0.004049360798531311\n",
      "97 0.004006080703238243\n",
      "98 0.00396369334200281\n",
      "99 0.003922171652105079\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "\n",
    "    #forward pass\n",
    "    ypred = [model(x) for x in xs]\n",
    "    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))     #mean-squared error\n",
    "\n",
    "    #backward pass\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # update - stocastic gradient descent\n",
    "    for p in model.parameters():\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    print(k, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9751764692749343),\n",
       " Value(data=-0.9570694876290724),\n",
       " Value(data=-0.9802211161119121),\n",
       " Value(data=0.9672626996507353)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4396f389b93e7269692bd3bea4c62813bbe379469bde939b058805f538feec11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
